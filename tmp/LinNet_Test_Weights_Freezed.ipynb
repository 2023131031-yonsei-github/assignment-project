{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision as tv"
      ],
      "metadata": {
        "id": "ToBrBLyfPDur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtb_HOjKOcqg",
        "outputId": "2de3f732-3c28-479b-d7fb-ce00c5eb1957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "def get_weights(bit_variant):\n",
        "  response = requests.get(f'https://storage.googleapis.com/bit_models/{bit_variant}.npz')\n",
        "  response.raise_for_status()\n",
        "  return np.load(io.BytesIO(response.content))\n",
        "\n",
        "weights = get_weights('BiT-M-R50x1')"
      ],
      "metadata": {
        "id": "JOpcgkODOe2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_cifar10 = get_weights('BiT-M-R50x1-CIFAR10')"
      ],
      "metadata": {
        "id": "jd0njZJuPPe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf2th(conv_weights):\n",
        "  \"\"\"Possibly convert HWIO to OIHW\"\"\"\n",
        "  if conv_weights.ndim == 4:\n",
        "    conv_weights = np.transpose(conv_weights, [3, 2, 0, 1])\n",
        "  return torch.from_numpy(conv_weights)\n",
        "\n",
        "class StdConv2d(nn.Conv2d):\n",
        "\n",
        "  def forward(self, x):\n",
        "    w = self.weight\n",
        "    v, m = torch.var_mean(w, dim=[1, 2, 3], keepdim=True, unbiased=False)\n",
        "    w = (w - m) / torch.sqrt(v + 1e-10)\n",
        "    return F.conv2d(x, w, self.bias, self.stride, self.padding,\n",
        "                    self.dilation, self.groups)\n",
        "\n",
        "def conv3x3(cin, cout, stride=1, groups=1, bias=False):\n",
        "  return StdConv2d(cin, cout, kernel_size=3, stride=stride, padding=1, bias=bias, groups=groups)\n",
        "\n",
        "def conv1x1(cin, cout, stride=1, bias=False):\n",
        "  return StdConv2d(cin, cout, kernel_size=1, stride=stride, padding=0, bias=bias)\n",
        "\n",
        "class PreActConv(nn.Module):\n",
        "\n",
        "  def __init__(self, cin, cout=None, cmid=None, stride=1):\n",
        "    super().__init__()\n",
        "    cout = cout or cin\n",
        "    cmid = cmid or cout//4\n",
        "\n",
        "    self.gn1 = nn.GroupNorm(32, cin)\n",
        "    self.conv1 = conv1x1(cin, cmid)\n",
        "    self.gn2 = nn.GroupNorm(32, cmid)\n",
        "    self.conv2 = conv3x3(cmid, cmid, stride)  # Original code has it on conv1!!\n",
        "    self.gn3 = nn.GroupNorm(32, cmid)\n",
        "    self.conv3 = conv1x1(cmid, cout)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.relu(self.gn1(x))\n",
        "\n",
        "    # Unit's branch\n",
        "    out = self.conv1(out)\n",
        "    out = self.conv2(self.relu(self.gn2(out)))\n",
        "    out = self.conv3(self.relu(self.gn3(out)))\n",
        "\n",
        "    return out\n",
        "\n",
        "  def load_from(self, weights, prefix=''):\n",
        "    with torch.no_grad():\n",
        "      self.conv1.weight.copy_(tf2th(weights[prefix + 'a/standardized_conv2d/kernel']))\n",
        "      self.conv2.weight.copy_(tf2th(weights[prefix + 'b/standardized_conv2d/kernel']))\n",
        "      self.conv3.weight.copy_(tf2th(weights[prefix + 'c/standardized_conv2d/kernel']))\n",
        "      self.gn1.weight.copy_(tf2th(weights[prefix + 'a/group_norm/gamma']))\n",
        "      self.gn2.weight.copy_(tf2th(weights[prefix + 'b/group_norm/gamma']))\n",
        "      self.gn3.weight.copy_(tf2th(weights[prefix + 'c/group_norm/gamma']))\n",
        "      self.gn1.bias.copy_(tf2th(weights[prefix + 'a/group_norm/beta']))\n",
        "      self.gn2.bias.copy_(tf2th(weights[prefix + 'b/group_norm/beta']))\n",
        "      self.gn3.bias.copy_(tf2th(weights[prefix + 'c/group_norm/beta']))\n",
        "      self.conv1.weight.requires_grad = False\n",
        "      self.conv2.weight.requires_grad = False\n",
        "      self.conv3.weight.requires_grad = False\n",
        "      self.gn1.weight.requires_grad = False\n",
        "      self.gn2.weight.requires_grad = False\n",
        "      self.gn3.weight.requires_grad = False\n",
        "      self.gn1.bias.requires_grad = False\n",
        "      self.gn2.bias.requires_grad = False\n",
        "      self.gn3.bias.requires_grad = False\n",
        "\n",
        "    return self\n",
        "  def melt(self):\n",
        "      self.conv1.weight.requires_grad = True\n",
        "      self.conv2.weight.requires_grad = True\n",
        "      self.conv3.weight.requires_grad = True\n",
        "      self.gn1.weight.requires_grad = True\n",
        "      self.gn2.weight.requires_grad = True\n",
        "      self.gn3.weight.requires_grad = True\n",
        "      self.gn1.bias.requires_grad = True\n",
        "      self.gn2.bias.requires_grad = True\n",
        "      self.gn3.bias.requires_grad = True\n",
        "  def freeze(self):\n",
        "      self.conv1.weight.requires_grad = False\n",
        "      self.conv2.weight.requires_grad = False\n",
        "      self.conv3.weight.requires_grad = False\n",
        "      self.gn1.weight.requires_grad = False\n",
        "      self.gn2.weight.requires_grad = False\n",
        "      self.gn3.weight.requires_grad = False\n",
        "      self.gn1.bias.requires_grad = False\n",
        "      self.gn2.bias.requires_grad = False\n",
        "      self.gn3.bias.requires_grad = False\n",
        "\n",
        "\n",
        "class ConvWithLin(nn.Module):\n",
        "  def __init__(self, lcin, cin, cout = None, cmid = None, lcout = None, stride=1, block_unit = 1):\n",
        "    super().__init__()\n",
        "    cout = cout or cin\n",
        "    cmid = cmid or cout//4\n",
        "    lcout = lcout or lcin\n",
        "\n",
        "    #self.unit = PreActConv(cin=cin,cout=cout,cmid=cmid,stride=stride)\n",
        "    if lcin != cin:\n",
        "      self.projin = conv1x1(lcin,cin,stride)\n",
        "\n",
        "    self.unit = nn.Sequential(OrderedDict(\n",
        "            [('unit01', PreActConv(cin=cin, cout=cout, cmid=cmid, stride=stride))] +\n",
        "            [(f'unit{i:02d}', PreActConv(cin=cout, cout=cout, cmid=cmid)) for i in range(2, block_unit + 1)],\n",
        "        ))\n",
        "    if lcout != cout:\n",
        "      self.projout = conv1x1(cout, lcout, stride)\n",
        "    if lcout != lcin:\n",
        "      self.linproj = conv1x1(lcin, lcout, stride)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    if hasattr(self, 'projin'):\n",
        "      out = self.projin(x)\n",
        "    else:\n",
        "      out = x\n",
        "\n",
        "    out = self.unit(out)\n",
        "\n",
        "    if hasattr(self, 'projout'):\n",
        "      out = self.projout(out)\n",
        "    if hasattr(self, 'linproj'):\n",
        "      x = self.linproj(x)\n",
        "\n",
        "    out = torch.add(out,x)\n",
        "\n",
        "#    if hasattr(self, 'outunit'):\n",
        "#      out = self.outunit(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class LinNet(nn.Module):\n",
        "  \"\"\"Implementation of Pre-activation (v2) ResNet mode.\"\"\"\n",
        "  BLOCK_UNITS = {\n",
        "      'r50': [3, 4, 6, 3],\n",
        "      'r101': [3, 4, 23, 3],\n",
        "      'r152': [3, 8, 36, 3],\n",
        "  }\n",
        "\n",
        "  def __init__(self, block_units, width_factor, head_size=21843, zero_head=False):\n",
        "    super().__init__()\n",
        "    wf = width_factor  # shortcut 'cause we'll use it a lot.\n",
        "\n",
        "    # The following will be unreadable if we split lines.\n",
        "    # pylint: disable=line-too-long\n",
        "    self.root = nn.Sequential(OrderedDict([\n",
        "        ('conv', StdConv2d(3, 64*wf, kernel_size=7, stride=2, padding=3, bias=False)),\n",
        "        ('pad', nn.ConstantPad2d(1, 0)),\n",
        "        ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=0)),\n",
        "        # The following is subtly not the same!\n",
        "        # ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "    ]))\n",
        "\n",
        "    self.body = nn.Sequential(OrderedDict([\n",
        "        ('block1', ConvWithLin(lcin = 64*wf, lcout=512*wf, cin=64*wf, cout= 256*wf, cmid=64*wf, block_unit = block_units[0])),\n",
        "        ('block2', ConvWithLin(lcin = 512*wf, lcout=512*wf, cin=256*wf, cout= 512*wf, cmid=128*wf, block_unit = block_units[1])),\n",
        "        ('block3', ConvWithLin(lcin = 512*wf, lcout=2048*wf, cin=512*wf, cout= 1024*wf, cmid=256*wf, block_unit = block_units[2])),\n",
        "        ('block4', ConvWithLin(lcin = 2048*wf, lcout=2048*wf, cin=1024*wf, cout= 2048*wf, cmid=512*wf, block_unit = block_units[3])),\n",
        "    ]))\n",
        "    # pylint: enable=line-too-long\n",
        "\n",
        "    self.zero_head = zero_head\n",
        "    self.head = nn.Sequential(OrderedDict([\n",
        "        ('gn', nn.GroupNorm(32, 2048*wf)),\n",
        "        ('relu', nn.ReLU(inplace=True)),\n",
        "        ('avg', nn.AdaptiveAvgPool2d(output_size=1)),\n",
        "        ('conv', nn.Conv2d(2048*wf, head_size, kernel_size=1, bias=True)),\n",
        "    ]))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.head(self.body(self.root(x)))\n",
        "    assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left.\n",
        "    return x[...,0,0]\n",
        "\n",
        "  def load_from(self, weights, prefix='resnet/'):\n",
        "    with torch.no_grad():\n",
        "      self.root.conv.weight.copy_(tf2th(weights[f'{prefix}root_block/standardized_conv2d/kernel']))\n",
        "      self.head.gn.weight.copy_(tf2th(weights[f'{prefix}group_norm/gamma']))\n",
        "      self.head.gn.bias.copy_(tf2th(weights[f'{prefix}group_norm/beta']))\n",
        "      if self.zero_head:\n",
        "        nn.init.zeros_(self.head.conv.weight)\n",
        "        nn.init.zeros_(self.head.conv.bias)\n",
        "      else:\n",
        "        self.head.conv.weight.copy_(tf2th(weights[f'{prefix}head/conv2d/kernel']))\n",
        "        self.head.conv.bias.copy_(tf2th(weights[f'{prefix}head/conv2d/bias']))\n",
        "\n",
        "      for bname, block in self.body.named_children():\n",
        "        for uname, unit in block.unit.named_children():\n",
        "          unit.load_from(weights, prefix=f'{prefix}{bname}/{uname}/')\n",
        "    return self\n"
      ],
      "metadata": {
        "id": "zc40fIvxOnHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinNet(LinNet.BLOCK_UNITS['r50'], width_factor=1, head_size=10,zero_head = True)  # NOTE: No new head.\n",
        "model.load_from(weights)\n",
        "model.to(device);"
      ],
      "metadata": {
        "id": "OFlgoM7IO4WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "IjgQrK-eOhxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "ISLiCWbnIYOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transform_train = T.Compose( [T.RandomCrop(32, padding=4), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n",
        "transform_test = T.Compose( [T.ToTensor(), T.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform_train )\n",
        "test_set = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform_test )\n",
        "\n",
        "classes = train_set.classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUYIfy3GH7q3",
        "outputId": "67483a8c-587a-4eeb-a6ec-ce38acd7803b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13482998.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate = 1e-3\n",
        "batch_size = 32\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "BHPCPw4uIitm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "S7EDuXPIH9VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "# Custom IPython progress bar for training\n",
        "class ProgressMonitor(object):\n",
        "\n",
        "    tmpl = \"\"\"\n",
        "        <table style=\"width: 100%;\">\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style=\"width: 30%;\">\n",
        "                     <b>Loss: {loss:0.4f}</b> &nbsp&nbsp&nbsp {value} / {length}\n",
        "                    </td>\n",
        "                    <td style=\"width: 70%;\">\n",
        "                        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "                    </td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "        self.count = 0\n",
        "        self.display = display(self.html(0, 0), display_id=True)\n",
        "\n",
        "    def html(self, count, loss):\n",
        "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
        "\n",
        "    def update(self, count, loss):\n",
        "        self.count += count\n",
        "        self.display.update(self.html(self.count, loss))"
      ],
      "metadata": {
        "id": "G6BnAx_jH9Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stairs(s, v, *svs):\n",
        "    \"\"\" Implements a typical \"stairs\" schedule for learning-rates.\n",
        "    Best explained by example:\n",
        "    stairs(s, 0.1, 10, 0.01, 20, 0.001)\n",
        "    will return 0.1 if s<10, 0.01 if 10<=s<20, and 0.001 if 20<=s\n",
        "    \"\"\"\n",
        "    for s0, v0 in zip(svs[::2], svs[1::2]):\n",
        "        if s < s0:\n",
        "            break\n",
        "        v = v0\n",
        "    return v\n",
        "\n",
        "def rampup(s, peak_s, peak_lr):\n",
        "  if s < peak_s:  # Warmup\n",
        "    return s/peak_s * peak_lr\n",
        "  else:\n",
        "    return peak_lr"
      ],
      "metadata": {
        "id": "WwDaQ3g4RhT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "\n",
        "optim = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.9, weight_decay=1e-6)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "S = 30\n",
        "def schedule(s):\n",
        "  step_lr = stairs(s, 3e-3, 10, 3e-4, 20, 3e-5, 25, 3e-6, S, None)\n",
        "  return rampup(s, 2, step_lr)\n",
        "\n",
        "def train(optimizer, model, num_epochs = 10, first_epoch = 1):\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    best_test_acc = 0\n",
        "\n",
        "    steps_per_batch = 50000 // train_loader.batch_size\n",
        "\n",
        "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
        "        print('Epoch', epoch)\n",
        "\n",
        "        model.train()\n",
        "        progress = ProgressMonitor(length=len(train_set))\n",
        "\n",
        "        correct_train = 0\n",
        "        batch_losses = []\n",
        "\n",
        "        lr = schedule(epoch)\n",
        "        for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] = lr\n",
        "\n",
        "        for batch, targets in train_loader:\n",
        "\n",
        "            batch = batch.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(batch)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            lossdiv = 5*loss/steps_per_batch\n",
        "            lossdiv.backward()\n",
        "\n",
        "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_train += torch.sum(preds == targets.data)\n",
        "            progress.update(batch.shape[0], mean(batch_losses) )\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        train_losses.append( mean(batch_losses))\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        y_pred = []\n",
        "\n",
        "        correct_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for batch, targets in test_loader:\n",
        "\n",
        "                # Move the training batch to the GPU\n",
        "                batch = batch.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # forward propagation\n",
        "                outputs = model(batch)\n",
        "\n",
        "                # calculate the loss\n",
        "                loss = loss_fn(outputs, targets)\n",
        "\n",
        "                # save predictions\n",
        "                y_pred.extend( outputs.argmax(dim=1).cpu().numpy() )\n",
        "\n",
        "                # accumulate correct count\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct_test += torch.sum(preds == targets.data)\n",
        "\n",
        "\n",
        "        # Calculate accuracy\n",
        "        train_acc = correct_train.item() / train_set.data.shape[0]\n",
        "        test_acc = correct_test.item() / test_set.data.shape[0]\n",
        "\n",
        "\n",
        "        print('Training accuracy: {:.2f}%'.format(float(train_acc) * 100))\n",
        "        print('Test accuracy: {:.2f}%'.format(float(test_acc) * 100))\n",
        "        print('Learning Rate: {:.7f}'.format(float(lr)), end='')\n",
        "\n",
        "        # Save the best model\n",
        "        if test_acc > best_test_acc:\n",
        "            best_test_acc = test_acc\n",
        "            torch.save( model.state_dict(), 'best_model.pt' )\n",
        "            print( ' --> Best model saved!\\n' )\n",
        "\n",
        "\n",
        "    return train_losses, test_losses, y_pred"
      ],
      "metadata": {
        "id": "IyC6jcThIDvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(optim, model=model, num_epochs = S-8,first_epoch=8)#, train_loader=train_loader,valid_loader=test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X0vI0fnmIFrn",
        "outputId": "64035f6d-fc64-4dac-f14a-ae780b9d09b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 2.1975</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 21.97%\n",
            "Test accuracy: 27.30%\n",
            "Learning Rate: 0.0030000 --> Best model saved!\n",
            "\n",
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 2.0674</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 27.92%\n",
            "Test accuracy: 30.94%\n",
            "Learning Rate: 0.0030000 --> Best model saved!\n",
            "\n",
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 2.0138</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 30.42%\n",
            "Test accuracy: 31.59%\n",
            "Learning Rate: 0.0003000 --> Best model saved!\n",
            "\n",
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 2.0068</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 30.12%\n",
            "Test accuracy: 31.85%\n",
            "Learning Rate: 0.0003000 --> Best model saved!\n",
            "\n",
            "Epoch 12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9991</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 30.80%\n",
            "Test accuracy: 32.23%\n",
            "Learning Rate: 0.0003000 --> Best model saved!\n",
            "\n",
            "Epoch 13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9914</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 30.75%\n",
            "Test accuracy: 32.08%\n",
            "Learning Rate: 0.0003000Epoch 14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9839</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.35%\n",
            "Test accuracy: 32.57%\n",
            "Learning Rate: 0.0003000 --> Best model saved!\n",
            "\n",
            "Epoch 15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9779</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 30.94%\n",
            "Test accuracy: 32.69%\n",
            "Learning Rate: 0.0003000 --> Best model saved!\n",
            "\n",
            "Epoch 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9706</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.32%\n",
            "Test accuracy: 32.49%\n",
            "Learning Rate: 0.0003000Epoch 17\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9650</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.33%\n",
            "Test accuracy: 32.66%\n",
            "Learning Rate: 0.0003000Epoch 18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9582</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.74%\n",
            "Test accuracy: 33.12%\n",
            "Learning Rate: 0.0003000 --> Best model saved!\n",
            "\n",
            "Epoch 19\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9526</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.78%\n",
            "Test accuracy: 32.85%\n",
            "Learning Rate: 0.0003000Epoch 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9490</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.67%\n",
            "Test accuracy: 32.99%\n",
            "Learning Rate: 0.0000300Epoch 21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9488</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.79%\n",
            "Test accuracy: 33.06%\n",
            "Learning Rate: 0.0000300Epoch 22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9463</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.99%\n",
            "Test accuracy: 33.16%\n",
            "Learning Rate: 0.0000300 --> Best model saved!\n",
            "\n",
            "Epoch 23\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9470</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.81%\n",
            "Test accuracy: 33.18%\n",
            "Learning Rate: 0.0000300 --> Best model saved!\n",
            "\n",
            "Epoch 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9466</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 32.08%\n",
            "Test accuracy: 33.18%\n",
            "Learning Rate: 0.0000300Epoch 25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9472</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 32.03%\n",
            "Test accuracy: 33.17%\n",
            "Learning Rate: 0.0000030Epoch 26\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9458</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.98%\n",
            "Test accuracy: 33.20%\n",
            "Learning Rate: 0.0000030 --> Best model saved!\n",
            "\n",
            "Epoch 27\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9443</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 32.10%\n",
            "Test accuracy: 33.18%\n",
            "Learning Rate: 0.0000030Epoch 28\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9466</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.91%\n",
            "Test accuracy: 33.18%\n",
            "Learning Rate: 0.0000030Epoch 29\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 1.9459</b> &nbsp&nbsp&nbsp 50000 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='50000' max='50000', style='width: 100%'>50000</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 31.73%\n",
            "Test accuracy: 33.18%\n",
            "Learning Rate: 0.0000030"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2.1974608042418615,\n",
              "  2.0673912695715693,\n",
              "  2.0138413563647184,\n",
              "  2.0067862925129827,\n",
              "  1.9990794996534946,\n",
              "  1.9913544908823757,\n",
              "  1.983885079641336,\n",
              "  1.9779379941375304,\n",
              "  1.9706326097688533,\n",
              "  1.964976764686277,\n",
              "  1.9581956427141556,\n",
              "  1.9526252201254828,\n",
              "  1.9489795899284397,\n",
              "  1.9487778221424465,\n",
              "  1.9462709202647437,\n",
              "  1.9470464488442556,\n",
              "  1.946609341632992,\n",
              "  1.9472332827494225,\n",
              "  1.9458300917863998,\n",
              "  1.9442824945950157,\n",
              "  1.9466296009581132,\n",
              "  1.9459392308273609],\n",
              " [],\n",
              " [2,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  9,\n",
              "  5,\n",
              "  7,\n",
              "  1,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  6,\n",
              "  7,\n",
              "  0,\n",
              "  8,\n",
              "  1,\n",
              "  4,\n",
              "  4,\n",
              "  3,\n",
              "  6,\n",
              "  9,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  5,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  5,\n",
              "  2,\n",
              "  4,\n",
              "  4,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  5,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  5,\n",
              "  5,\n",
              "  8,\n",
              "  8,\n",
              "  8,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  2,\n",
              "  0,\n",
              "  8,\n",
              "  9,\n",
              "  8,\n",
              "  0,\n",
              "  2,\n",
              "  8,\n",
              "  2,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  4,\n",
              "  3,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  1,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  6,\n",
              "  1,\n",
              "  2,\n",
              "  9,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  4,\n",
              "  2,\n",
              "  4,\n",
              "  9,\n",
              "  9,\n",
              "  9,\n",
              "  0,\n",
              "  2,\n",
              "  9,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  6,\n",
              "  5,\n",
              "  9,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  6,\n",
              "  5,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  6,\n",
              "  2,\n",
              "  9,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  8,\n",
              "  6,\n",
              "  5,\n",
              "  8,\n",
              "  1,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  1,\n",
              "  9,\n",
              "  0,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  6,\n",
              "  2,\n",
              "  9,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  8,\n",
              "  0,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  1,\n",
              "  5,\n",
              "  2,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  9,\n",
              "  8,\n",
              "  2,\n",
              "  7,\n",
              "  6,\n",
              "  5,\n",
              "  2,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  5,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  5,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  8,\n",
              "  5,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  2,\n",
              "  5,\n",
              "  7,\n",
              "  6,\n",
              "  2,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  9,\n",
              "  1,\n",
              "  6,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  0,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  8,\n",
              "  5,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  5,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  9,\n",
              "  1,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  9,\n",
              "  1,\n",
              "  2,\n",
              "  5,\n",
              "  0,\n",
              "  5,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  1,\n",
              "  2,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  4,\n",
              "  1,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  6,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  2,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  7,\n",
              "  4,\n",
              "  0,\n",
              "  1,\n",
              "  9,\n",
              "  8,\n",
              "  8,\n",
              "  9,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  2,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  5,\n",
              "  8,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  8,\n",
              "  5,\n",
              "  4,\n",
              "  9,\n",
              "  9,\n",
              "  4,\n",
              "  2,\n",
              "  6,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  8,\n",
              "  9,\n",
              "  2,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  5,\n",
              "  1,\n",
              "  9,\n",
              "  8,\n",
              "  8,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  5,\n",
              "  2,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  8,\n",
              "  5,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  1,\n",
              "  5,\n",
              "  5,\n",
              "  2,\n",
              "  7,\n",
              "  7,\n",
              "  5,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  0,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  6,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  9,\n",
              "  2,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  6,\n",
              "  9,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  9,\n",
              "  9,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  9,\n",
              "  0,\n",
              "  5,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  5,\n",
              "  2,\n",
              "  8,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  2,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  5,\n",
              "  5,\n",
              "  8,\n",
              "  9,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  0,\n",
              "  9,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  6,\n",
              "  4,\n",
              "  2,\n",
              "  8,\n",
              "  1,\n",
              "  9,\n",
              "  5,\n",
              "  6,\n",
              "  5,\n",
              "  2,\n",
              "  9,\n",
              "  1,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  9,\n",
              "  8,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  2,\n",
              "  0,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  2,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  5,\n",
              "  6,\n",
              "  5,\n",
              "  4,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  2,\n",
              "  8,\n",
              "  9,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  9,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  0,\n",
              "  5,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  3,\n",
              "  2,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  6,\n",
              "  0,\n",
              "  9,\n",
              "  4,\n",
              "  2,\n",
              "  9,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  1,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  5,\n",
              "  0,\n",
              "  9,\n",
              "  6,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  2,\n",
              "  8,\n",
              "  5,\n",
              "  4,\n",
              "  5,\n",
              "  0,\n",
              "  1,\n",
              "  5,\n",
              "  6,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  5,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  0,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  9,\n",
              "  7,\n",
              "  6,\n",
              "  8,\n",
              "  8,\n",
              "  9,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  6,\n",
              "  6,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  8,\n",
              "  2,\n",
              "  0,\n",
              "  8,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  6,\n",
              "  8,\n",
              "  8,\n",
              "  8,\n",
              "  0,\n",
              "  8,\n",
              "  1,\n",
              "  2,\n",
              "  4,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  5,\n",
              "  5,\n",
              "  7,\n",
              "  1,\n",
              "  7,\n",
              "  4,\n",
              "  6,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  0,\n",
              "  1,\n",
              "  9,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  5,\n",
              "  9,\n",
              "  2,\n",
              "  8,\n",
              "  9,\n",
              "  8,\n",
              "  2,\n",
              "  6,\n",
              "  0,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  0,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  2,\n",
              "  4,\n",
              "  0,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  1,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  4,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  4,\n",
              "  2,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  8,\n",
              "  6,\n",
              "  5,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  4,\n",
              "  5,\n",
              "  0,\n",
              "  4,\n",
              "  2,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  1,\n",
              "  0,\n",
              "  2,\n",
              "  0,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  0,\n",
              "  2,\n",
              "  5,\n",
              "  0,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  8,\n",
              "  8,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  1,\n",
              "  4,\n",
              "  0,\n",
              "  5,\n",
              "  8,\n",
              "  4,\n",
              "  5,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  9,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  5,\n",
              "  5,\n",
              "  4,\n",
              "  2,\n",
              "  6,\n",
              "  3,\n",
              "  8,\n",
              "  6,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  6,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  4,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  2,\n",
              "  5,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  5,\n",
              "  2,\n",
              "  7,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  0,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  9,\n",
              "  2,\n",
              "  1,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  4,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  1,\n",
              "  4,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  1,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  6,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  2,\n",
              "  8,\n",
              "  1,\n",
              "  6,\n",
              "  8,\n",
              "  ...])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"PATH.pt\")"
      ],
      "metadata": {
        "id": "3n9cdtjzUKBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"PATH1.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erf_Nsf0UKfs",
        "outputId": "71b783ef-5770-44b4-9074-523a378b2f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinNet(\n",
              "  (root): Sequential(\n",
              "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0)\n",
              "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (body): Sequential(\n",
              "    (block1): ConvWithLin(\n",
              "      (unit): Sequential(\n",
              "        (unit01): PreActConv(\n",
              "          (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit02): PreActConv(\n",
              "          (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit03): PreActConv(\n",
              "          (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (projout): StdConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (linproj): StdConv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (block2): ConvWithLin(\n",
              "      (projin): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (unit): Sequential(\n",
              "        (unit01): PreActConv(\n",
              "          (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit02): PreActConv(\n",
              "          (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit03): PreActConv(\n",
              "          (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit04): PreActConv(\n",
              "          (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (block3): ConvWithLin(\n",
              "      (unit): Sequential(\n",
              "        (unit01): PreActConv(\n",
              "          (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit02): PreActConv(\n",
              "          (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit03): PreActConv(\n",
              "          (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit04): PreActConv(\n",
              "          (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit05): PreActConv(\n",
              "          (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit06): PreActConv(\n",
              "          (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (projout): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (linproj): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    )\n",
              "    (block4): ConvWithLin(\n",
              "      (projin): StdConv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (unit): Sequential(\n",
              "        (unit01): PreActConv(\n",
              "          (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit02): PreActConv(\n",
              "          (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (unit03): PreActConv(\n",
              "          (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
              "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Sequential(\n",
              "    (gn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (avg): AdaptiveAvgPool2d(output_size=1)\n",
              "    (conv): Conv2d(2048, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for bname, block in model.body.named_children():\n",
        "  for uname, unit in block.unit.named_children():\n",
        "    unit.melt()"
      ],
      "metadata": {
        "id": "3Z-9sBpmW6bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for bname, block in model.body.named_children():\n",
        "  for uname, unit in block.unit.named_children():\n",
        "    #unit.load_from(weights, prefix=f'resnet/{bname}/{uname}/')\n",
        "    t1 = tf2th(weights[f'resnet/{bname}/{uname}/' + 'a/standardized_conv2d/kernel']).to(device)\n",
        "    print(torch.equal(unit.conv1.weight,t1))\n",
        "    print(t1.shape)\n",
        "    print(unit.conv1.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_OqKJkVVl_l",
        "outputId": "567a537c-3ed4-4995-d219-18844bfe6ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "torch.Size([64, 64, 1, 1])\n",
            "torch.Size([64, 64, 1, 1])\n",
            "False\n",
            "torch.Size([64, 256, 1, 1])\n",
            "torch.Size([64, 256, 1, 1])\n",
            "False\n",
            "torch.Size([64, 256, 1, 1])\n",
            "torch.Size([64, 256, 1, 1])\n",
            "False\n",
            "torch.Size([128, 256, 1, 1])\n",
            "torch.Size([128, 256, 1, 1])\n",
            "False\n",
            "torch.Size([128, 512, 1, 1])\n",
            "torch.Size([128, 512, 1, 1])\n",
            "False\n",
            "torch.Size([128, 512, 1, 1])\n",
            "torch.Size([128, 512, 1, 1])\n",
            "False\n",
            "torch.Size([128, 512, 1, 1])\n",
            "torch.Size([128, 512, 1, 1])\n",
            "False\n",
            "torch.Size([256, 512, 1, 1])\n",
            "torch.Size([256, 512, 1, 1])\n",
            "False\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "False\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "False\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "False\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "False\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "torch.Size([256, 1024, 1, 1])\n",
            "False\n",
            "torch.Size([512, 1024, 1, 1])\n",
            "torch.Size([512, 1024, 1, 1])\n",
            "False\n",
            "torch.Size([512, 2048, 1, 1])\n",
            "torch.Size([512, 2048, 1, 1])\n",
            "False\n",
            "torch.Size([512, 2048, 1, 1])\n",
            "torch.Size([512, 2048, 1, 1])\n"
          ]
        }
      ]
    }
  ]
}
